{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/pytorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from datasets import load_dataset, IterableDatasetDict, Audio, DatasetDict, Dataset\n",
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ðŸ¤— Datasets, downloading and preparing data is extremely simple. \n",
    "We can download and prepare the Common Voice splits in just one line of code. \n",
    "\n",
    "First, ensure you have accepted the terms of use on the Hugging Face Hub: [mozilla-foundation/common_voice_11_0](https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0). Once you have accepted the terms, you will have full access to the dataset and be able to download the data locally.\n",
    "\n",
    "Since Hindi is very low-resource, we'll combine the `train` and `validation` \n",
    "splits to give approximately 8 hours of training data. We'll use the 4 hours \n",
    "of `test` data as our held-out test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <datasets.iterable_dataset.IterableDataset object at 0x7fefa4498e50>, 'test': <datasets.iterable_dataset.IterableDataset object at 0x7feec3ebe210>}\n"
     ]
    }
   ],
   "source": [
    "common_voice = IterableDatasetDict()\n",
    "\n",
    "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"es\", split=\"train\", token=\"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\", streaming=True)\n",
    "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"es\", split=\"test\", token=\"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\", streaming=True)\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <datasets.iterable_dataset.IterableDataset object at 0x7feeb15210d0>, 'test': <datasets.iterable_dataset.IterableDataset object at 0x7feeb1523d50>}\n"
     ]
    }
   ],
   "source": [
    "common_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since \n",
    "our input audio is sampled at 48kHz, we need to _downsample_ it to \n",
    "16kHz prior to passing it to the Whisper feature extractor, 16kHz being the sampling rate expected by the Whisper model. \n",
    "\n",
    "We'll set the audio inputs to the correct sampling rate using dataset's \n",
    "[`cast_column`](https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=cast_column#datasets.DatasetDict.cast_column)\n",
    "method. This operation does not change the audio in-place, \n",
    "but rather signals to `datasets` to resample audio samples _on the fly_ the \n",
    "first time that they are loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the audio to 16kHz\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load WhisperFeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Whisper feature extractor performs two operations:\n",
    "1. Pads / truncates the audio inputs to 30s: any audio inputs shorter than 30s are padded to 30s with silence (zeros), and those longer that 30s are truncated to 30s\n",
    "2. Converts the audio inputs to _log-Mel spectrogram_ input features, a visual representation of the audio and the form of the input expected by the Whisper model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/sanchit-gandhi/notebooks/main/spectrogram.jpg\" alt=\"Trulli\" style=\"width:100%\">\n",
    "<figcaption align = \"center\"><b>Figure 2:</b> Conversion of sampled audio array to log-Mel spectrogram.\n",
    "Left: sampled 1-dimensional audio signal. Right: corresponding log-Mel spectrogram. Figure source:\n",
    "<a href=\"https://ai.googleblog.com/2019/04/specaugment-new-data-augmentation.html\">Google SpecAugment Blog</a>.\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load the feature extractor from the pre-trained checkpoint with the default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load WhisperTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Whisper model outputs a sequence of _token ids_. The tokenizer maps each of these token ids to their corresponding text string. For Hindi, we can load the pre-trained tokenizer and use it for fine-tuning without any further modifications. We simply have to \n",
    "specify the target language and the task. These arguments inform the \n",
    "tokenizer to prefix the language and task tokens to the start of encoded \n",
    "label sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-base\", language=\"Spanish\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the first example of the Common Voice dataset to see \n",
    "what form the data is in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(common_voice[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write a function to prepare our data ready for the model:\n",
    "1. We load and resample the audio data by calling `batch[\"audio\"]`. As explained above, ðŸ¤— Datasets performs any necessary resampling operations on the fly.\n",
    "2. We use the feature extractor to compute the log-Mel spectrogram input features from our 1-dimensional audio array.\n",
    "3. We encode the transcriptions to label ids through the use of the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_common_voice_11_0(batch): \n",
    "    \"\"\"Function to preprocess the dataset with the .map method\"\"\"\n",
    "    # Prepare dataset provided by Mozilla Common Voice 11.0\n",
    "    # source: https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0#data-preprocessing-recommended-by-hugging-face\n",
    "    transcription = batch[\"sentence\"]\n",
    "\n",
    "    if transcription.startswith('\"') and transcription.endswith('\"'):\n",
    "        # we can remove trailing quotation marks as they do not affect the transcription\n",
    "        transcription = transcription[1:-1]\n",
    "\n",
    "    if transcription[-1] not in [\".\", \"?\", \"!\"]:\n",
    "        # append a full-stop to sentences that do not end in punctuation\n",
    "        transcription = transcription + \".\"\n",
    "\n",
    "    batch[\"sentence\"] = transcription\n",
    "\n",
    "    return batch\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids \n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "def prepare_combined_dataset(batch):\n",
    "    # Chain the two prepare functions\n",
    "    return prepare_dataset(prepare_dataset_common_voice_11_0(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply the data preparation function to all of our training examples using dataset's `.map` method. The argument `num_proc` specifies how many CPU cores to use. Setting `num_proc` > 1 will enable multiprocessing. If the `.map` method hangs with multiprocessing, set `num_proc=1` and process the dataset sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataset to 5000 examples\n",
    "common_voice = common_voice.filter(lambda _example, idx: idx < 5000, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=2)\n",
    "common_voice = common_voice.map(prepare_combined_dataset, remove_columns=common_voice[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <datasets.iterable_dataset.IterableDataset at 0x7feeb0414ed0>,\n",
       " 'test': <datasets.iterable_dataset.IterableDataset at 0x7feeb04153d0>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'generator' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/BlondeFer/Documents/Master/2_2/ID2223/Assignment_2/feature_extraction.ipynb Cell 25\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/BlondeFer/Documents/Master/2_2/ID2223/Assignment_2/feature_extraction.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# to_store[\"train\"] = Dataset.from_dict(dict(common_voice[\"train\"]))\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/BlondeFer/Documents/Master/2_2/ID2223/Assignment_2/feature_extraction.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m iter_train \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(common_voice[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/BlondeFer/Documents/Master/2_2/ID2223/Assignment_2/feature_extraction.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m to_store[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39;49mfrom_generator(\u001b[39mlambda\u001b[39;49;00m: \u001b[39mnext\u001b[39;49m(iter_train))\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/arrow_dataset.py:1064\u001b[0m, in \u001b[0;36mDataset.from_generator\u001b[0;34m(generator, features, cache_dir, keep_in_memory, gen_kwargs, num_proc, **kwargs)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Create a Dataset from a generator.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \n\u001b[1;32m   1017\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgenerator\u001b[39;00m \u001b[39mimport\u001b[39;00m GeneratorDatasetInputStream\n\u001b[0;32m-> 1064\u001b[0m \u001b[39mreturn\u001b[39;00m GeneratorDatasetInputStream(\n\u001b[1;32m   1065\u001b[0m     generator\u001b[39m=\u001b[39;49mgenerator,\n\u001b[1;32m   1066\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   1067\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1068\u001b[0m     keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m   1069\u001b[0m     gen_kwargs\u001b[39m=\u001b[39;49mgen_kwargs,\n\u001b[1;32m   1070\u001b[0m     num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m   1071\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1072\u001b[0m )\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/io/generator.py:28\u001b[0m, in \u001b[0;36mGeneratorDatasetInputStream.__init__\u001b[0;34m(self, generator, features, cache_dir, keep_in_memory, streaming, gen_kwargs, num_proc, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     10\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     11\u001b[0m     generator: Callable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m     19\u001b[0m ):\n\u001b[1;32m     20\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m     21\u001b[0m         features\u001b[39m=\u001b[39mfeatures,\n\u001b[1;32m     22\u001b[0m         cache_dir\u001b[39m=\u001b[39mcache_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m     27\u001b[0m     )\n\u001b[0;32m---> 28\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder \u001b[39m=\u001b[39m Generator(\n\u001b[1;32m     29\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m     30\u001b[0m         features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m     31\u001b[0m         generator\u001b[39m=\u001b[39;49mgenerator,\n\u001b[1;32m     32\u001b[0m         gen_kwargs\u001b[39m=\u001b[39;49mgen_kwargs,\n\u001b[1;32m     33\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     34\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/builder.py:373\u001b[0m, in \u001b[0;36mDatasetBuilder.__init__\u001b[0;34m(self, cache_dir, dataset_name, config_name, hash, base_path, info, features, token, use_auth_token, repo_id, data_files, data_dir, storage_options, writer_batch_size, name, **config_kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39mif\u001b[39;00m data_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    372\u001b[0m     config_kwargs[\u001b[39m\"\u001b[39m\u001b[39mdata_dir\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m data_dir\n\u001b[0;32m--> 373\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_builder_config(\n\u001b[1;32m    374\u001b[0m     config_name\u001b[39m=\u001b[39;49mconfig_name,\n\u001b[1;32m    375\u001b[0m     custom_features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m    376\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig_kwargs,\n\u001b[1;32m    377\u001b[0m )\n\u001b[1;32m    379\u001b[0m \u001b[39m# prepare info: DatasetInfo are a standardized dataclass across all datasets\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# Prefill datasetinfo\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m info \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m     \u001b[39m# TODO FOR PACKAGED MODULES IT IMPORTS DATA FROM src/packaged_modules which doesn't make sense\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/builder.py:568\u001b[0m, in \u001b[0;36mDatasetBuilder._create_builder_config\u001b[0;34m(self, config_name, custom_features, **config_kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBuilderConfig must have a name, got \u001b[39m\u001b[39m{\u001b[39;00mbuilder_config\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    567\u001b[0m \u001b[39m# compute the config id that is going to be used for caching\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m config_id \u001b[39m=\u001b[39m builder_config\u001b[39m.\u001b[39;49mcreate_config_id(\n\u001b[1;32m    569\u001b[0m     config_kwargs,\n\u001b[1;32m    570\u001b[0m     custom_features\u001b[39m=\u001b[39;49mcustom_features,\n\u001b[1;32m    571\u001b[0m )\n\u001b[1;32m    572\u001b[0m is_custom \u001b[39m=\u001b[39m (config_id \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder_configs) \u001b[39mand\u001b[39;00m config_id \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m \u001b[39mif\u001b[39;00m is_custom:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/builder.py:198\u001b[0m, in \u001b[0;36mBuilderConfig.create_config_id\u001b[0;34m(self, config_kwargs, custom_features)\u001b[0m\n\u001b[1;32m    196\u001b[0m             suffix \u001b[39m=\u001b[39m Hasher\u001b[39m.\u001b[39mhash(config_kwargs_to_add_to_suffix)\n\u001b[1;32m    197\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m         suffix \u001b[39m=\u001b[39m Hasher\u001b[39m.\u001b[39;49mhash(config_kwargs_to_add_to_suffix)\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m custom_features \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     m \u001b[39m=\u001b[39m Hasher()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/fingerprint.py:236\u001b[0m, in \u001b[0;36mHasher.hash\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mdispatch[\u001b[39mtype\u001b[39m(value)](\u001b[39mcls\u001b[39m, value)\n\u001b[1;32m    235\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mhash_default(value)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/fingerprint.py:229\u001b[0m, in \u001b[0;36mHasher.hash_default\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhash_default\u001b[39m(\u001b[39mcls\u001b[39m, value: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m--> 229\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mhash_bytes(dumps(value))\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/utils/py_utils.py:727\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    725\u001b[0m file \u001b[39m=\u001b[39m StringIO()\n\u001b[1;32m    726\u001b[0m \u001b[39mwith\u001b[39;00m _no_cache_fields(obj):\n\u001b[0;32m--> 727\u001b[0m     dump(obj, file)\n\u001b[1;32m    728\u001b[0m \u001b[39mreturn\u001b[39;00m file\u001b[39m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/utils/py_utils.py:702\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file):\n\u001b[1;32m    701\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"pickle an object to a file\"\"\"\u001b[39;00m\n\u001b[0;32m--> 702\u001b[0m     Pickler(file, recurse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39;49mdump(obj)\n\u001b[1;32m    703\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/dill/_dill.py:418\u001b[0m, in \u001b[0;36mPickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(\u001b[39mself\u001b[39m, obj): \u001b[39m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     logger\u001b[39m.\u001b[39mtrace_setup(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 418\u001b[0m     StockPickler\u001b[39m.\u001b[39;49mdump(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[1;32m    486\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mstart_framing()\n\u001b[0;32m--> 487\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave(obj)\n\u001b[1;32m    488\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(STOP)\n\u001b[1;32m    489\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mend_framing()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/utils/py_utils.py:692\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    690\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m dill\u001b[39m.\u001b[39;49mPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id\u001b[39m=\u001b[39;49msave_persistent_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/dill/_dill.py:412\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    410\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    411\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 412\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/dill/_dill.py:1212\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[1;32m   1210\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1212\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[1;32m   1213\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1214\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/pickle.py:972\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[1;32m    971\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 972\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/pickle.py:998\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m    997\u001b[0m         save(k)\n\u001b[0;32m--> 998\u001b[0m         save(v)\n\u001b[1;32m    999\u001b[0m     write(SETITEMS)\n\u001b[1;32m   1000\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/utils/py_utils.py:692\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    690\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m dill\u001b[39m.\u001b[39;49mPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id\u001b[39m=\u001b[39;49msave_persistent_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/dill/_dill.py:412\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    410\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    411\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 412\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/utils/py_utils.py:1335\u001b[0m, in \u001b[0;36msave_function\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m state_dict:\n\u001b[1;32m   1333\u001b[0m     state \u001b[39m=\u001b[39m state, state_dict\n\u001b[0;32m-> 1335\u001b[0m dill\u001b[39m.\u001b[39;49m_dill\u001b[39m.\u001b[39;49m_save_with_postproc(\n\u001b[1;32m   1336\u001b[0m     pickler,\n\u001b[1;32m   1337\u001b[0m     (dill\u001b[39m.\u001b[39;49m_dill\u001b[39m.\u001b[39;49m_create_function, (obj\u001b[39m.\u001b[39;49m\u001b[39m__code__\u001b[39;49m, globs, obj\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m, obj\u001b[39m.\u001b[39;49m\u001b[39m__defaults__\u001b[39;49m, closure), state),\n\u001b[1;32m   1338\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1339\u001b[0m     postproc_list\u001b[39m=\u001b[39;49mpostproc_list,\n\u001b[1;32m   1340\u001b[0m )\n\u001b[1;32m   1342\u001b[0m \u001b[39m# Lift closure cell update to earliest function (#458)\u001b[39;00m\n\u001b[1;32m   1343\u001b[0m \u001b[39mif\u001b[39;00m _postproc:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/dill/_dill.py:1107\u001b[0m, in \u001b[0;36m_save_with_postproc\u001b[0;34m(pickler, reduction, is_pickler_dill, obj, postproc_list)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[39mif\u001b[39;00m source:\n\u001b[1;32m   1106\u001b[0m     pickler\u001b[39m.\u001b[39mwrite(pickler\u001b[39m.\u001b[39mget(pickler\u001b[39m.\u001b[39mmemo[\u001b[39mid\u001b[39m(dest)][\u001b[39m0\u001b[39m]))\n\u001b[0;32m-> 1107\u001b[0m     pickler\u001b[39m.\u001b[39;49m_batch_setitems(\u001b[39miter\u001b[39;49m(source\u001b[39m.\u001b[39;49mitems()))\n\u001b[1;32m   1108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# Updating with an empty dictionary. Same as doing nothing.\u001b[39;00m\n\u001b[1;32m   1110\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/pickle.py:998\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m    997\u001b[0m         save(k)\n\u001b[0;32m--> 998\u001b[0m         save(v)\n\u001b[1;32m    999\u001b[0m     write(SETITEMS)\n\u001b[1;32m   1000\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/utils/py_utils.py:692\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    690\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m dill\u001b[39m.\u001b[39;49mPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id\u001b[39m=\u001b[39;49msave_persistent_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/dill/_dill.py:412\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    410\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: attribute lookup builtins.generator failed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m GeneratorType\n\u001b[1;32m    411\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 412\u001b[0m StockPickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj, save_persistent_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/pickle.py:578\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    576\u001b[0m reduce \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m__reduce_ex__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m     rv \u001b[39m=\u001b[39m reduce(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto)\n\u001b[1;32m    579\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    580\u001b[0m     reduce \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m__reduce__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'generator' object"
     ]
    }
   ],
   "source": [
    "# Iterate over the dataset and stores all the samples in disk\n",
    "for split in common_voice.keys():\n",
    "    common_voice[split].save_to_disk(f\"common_voice_{split}_16kHz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'IterableDataset' object has no attribute 'save_to_disk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/BlondeFer/Documents/Master/2_2/ID2223/Assignment_2/feature_extraction.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/BlondeFer/Documents/Master/2_2/ID2223/Assignment_2/feature_extraction.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m to_store\u001b[39m.\u001b[39;49msave_to_disk(\u001b[39m\"\u001b[39;49m\u001b[39mcommon_voice_es\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/datasets/dataset_dict.py:1276\u001b[0m, in \u001b[0;36mDatasetDict.save_to_disk\u001b[0;34m(self, dataset_dict_path, fs, max_shard_size, num_shards, num_proc, storage_options)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     json\u001b[39m.\u001b[39mdump({\u001b[39m\"\u001b[39m\u001b[39msplits\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m)}, f)\n\u001b[1;32m   1275\u001b[0m \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems():\n\u001b[0;32m-> 1276\u001b[0m     dataset\u001b[39m.\u001b[39;49msave_to_disk(\n\u001b[1;32m   1277\u001b[0m         posixpath\u001b[39m.\u001b[39mjoin(dataset_dict_path, k),\n\u001b[1;32m   1278\u001b[0m         num_shards\u001b[39m=\u001b[39mnum_shards\u001b[39m.\u001b[39mget(k),\n\u001b[1;32m   1279\u001b[0m         max_shard_size\u001b[39m=\u001b[39mmax_shard_size,\n\u001b[1;32m   1280\u001b[0m         num_proc\u001b[39m=\u001b[39mnum_proc,\n\u001b[1;32m   1281\u001b[0m         storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[1;32m   1282\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'IterableDataset' object has no attribute 'save_to_disk'"
     ]
    }
   ],
   "source": [
    "to_store.save_to_disk(\"common_voice_es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/BlondeFer/Documents/Master/2_2/ID2223/Assignment_2\n",
      "['dataset_dict.json', 'test', 'train']\n",
      "['data-00000-of-00029.arrow', 'data-00001-of-00029.arrow', 'data-00002-of-00029.arrow', 'data-00003-of-00029.arrow', 'data-00004-of-00029.arrow', 'data-00005-of-00029.arrow', 'data-00006-of-00029.arrow', 'data-00007-of-00029.arrow', 'data-00008-of-00029.arrow', 'data-00009-of-00029.arrow', 'data-00010-of-00029.arrow', 'data-00011-of-00029.arrow', 'data-00012-of-00029.arrow', 'data-00013-of-00029.arrow', 'data-00014-of-00029.arrow', 'data-00015-of-00029.arrow', 'data-00016-of-00029.arrow', 'data-00017-of-00029.arrow', 'data-00018-of-00029.arrow', 'data-00019-of-00029.arrow', 'data-00020-of-00029.arrow', 'data-00021-of-00029.arrow', 'data-00022-of-00029.arrow', 'data-00023-of-00029.arrow', 'data-00024-of-00029.arrow', 'data-00025-of-00029.arrow', 'data-00026-of-00029.arrow', 'data-00027-of-00029.arrow', 'data-00028-of-00029.arrow', 'dataset_info.json', 'state.json']\n",
      "['data-00000-of-00012.arrow', 'data-00001-of-00012.arrow', 'data-00002-of-00012.arrow', 'data-00003-of-00012.arrow', 'data-00004-of-00012.arrow', 'data-00005-of-00012.arrow', 'data-00006-of-00012.arrow', 'data-00007-of-00012.arrow', 'data-00008-of-00012.arrow', 'data-00009-of-00012.arrow', 'data-00010-of-00012.arrow', 'data-00011-of-00012.arrow', 'dataset_info.json', 'state.json']\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "print(os.listdir(\"./combined_dataset/\"))\n",
    "print(os.listdir(\"./combined_dataset/train\"))\n",
    "print(os.listdir(\"./combined_dataset/test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.7GiB\n"
     ]
    }
   ],
   "source": [
    "def get_dir_size(path):\n",
    "    total = 0\n",
    "    with os.scandir(path) as it:\n",
    "        for entry in it:\n",
    "            if entry.is_file():\n",
    "                total += entry.stat().st_size\n",
    "            elif entry.is_dir():\n",
    "                total += get_dir_size(entry.path)\n",
    "    return total\n",
    "\n",
    "def sizeof_fmt(num, suffix=\"B\"):\n",
    "    # Source: https://web.archive.org/web/20111010015624/http://blogmag.net/blog/read/38/Print_human_readable_file_size\n",
    "    for unit in (\"\", \"Ki\", \"Mi\", \"Gi\", \"Ti\"):\n",
    "        if abs(num) < 1024.0:\n",
    "            return f\"{num:3.1f}{unit}{suffix}\"\n",
    "        num /= 1024.0\n",
    "    # If we get here, the size is too large to be represented as a PiB value\n",
    "    return f\"{num:.1f}Pi{suffix}\"\n",
    "\n",
    "\n",
    "sz = get_dir_size(\"./combined_dataset/\")\n",
    "print(sizeof_fmt(sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
